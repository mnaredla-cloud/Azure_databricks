{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOHw/uvDqHjwtzxJp/5AGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnaredla-cloud/Azure_databricks/blob/main/11)Auto_Tokenizer_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dhJUu_h5x5l2"
      },
      "outputs": [],
      "source": [
        "### Extracting_Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Extracting Tokens, by padding o's at the end to match the length\n",
        "\n",
        "#padding = True >>adds 0's at the end\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "classifier = pipeline(task=\"sentiment-analysis\")\n",
        "\n",
        "review = [\"This is a very good movie\",\"I like this movie\"]\n",
        "\n",
        "\n",
        "#tokenizer gives tokens\n",
        "tokenizer = classifier.tokenizer\n",
        "tokens = tokenizer(review, padding = True, return_tensors = \"pt\")\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "#encode gives token_id's\n",
        "tokenizer_id = classifier.tokenizer.encode\n",
        "tokens_ids = tokenizer_id(review, padding = True, return_tensors = \"pt\")\n",
        "print(tokens_ids)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hya8HM4JyHjc",
        "outputId": "0570d6b3-dd9f-45cf-9371-67c2ddc68544"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 2200, 2204, 3185,  102],\n",
            "        [ 101, 1045, 2066, 2023, 3185,  102,    0,    0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0]])}\n",
            "tensor([[ 101, 2023, 2003, 1037, 2200, 2204, 3185,  102, 1045, 2066, 2023, 3185,\n",
            "          102]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Auto_Tokenizer\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "review = [\"This is a very good movie\",\"I like this movie\"]\n",
        "\n",
        "result = tokenizer(review, padding = True, return_tensors = \"pt\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsiHbD63yLFF",
        "outputId": "aee92713-06c3-4476-afed-4a9d3e082373"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 101, 1188, 1110,  170, 1304, 1363, 2523,  102],\n",
            "        [ 101,  146, 1176, 1142, 2523,  102,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 0, 0]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Auto_Model\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHeo00sp6JGA",
        "outputId": "a00fe38b-bf20-44b1-e306-a49248a0fd18"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSdpaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    }
  ]
}